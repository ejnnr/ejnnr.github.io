---
title: ML Reproducibility Challenge
summary: Replication of an ML fairness paper together with other Master's students.
tags:
- Deep Learning
- Fairness
date: "2020-07-01"
show_date: false

# Optional external URL for project (replaces project detail page).
external_link: ""

links:
- name: Code
  icon: github
  icon_pack: fab
  url: https://github.com/TomFrederik/fact-ai
url_slides: ""
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""
---

As part of the course *Fairness, Accountability, Confidentiality and Transparency in AI*
at the University of Amsterdam, I replicated the paper
[Fairness without Demographics through Adversarially Reweighted Learning](https://arxiv.org/abs/2006.13114)
(Lahoti et al., 2020) together with three other Master's students.
We also performed additional experiments to test whether the method transfers
from tabular to image data. We wrote a report with our findings for the
[ML Reproducibility Challenge 2020](https://paperswithcode.com/rc2020).
