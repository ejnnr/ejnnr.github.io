<!DOCTYPE html>
<html lang="en">
  <head>
    
      <title>Distributions Part I: the Delta distribution :: Erik Jenner</title>
    
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="description" content="Schwartz distributions are a generalization of functions from \(\mathbb{R}^n\) to \(\mathbb{R}\): strictly speaking, they aren&amp;rsquo;t such functions themselves, but you can do a lot of the same stuff with them that you can do with normal functions, such as taking derivatives, computing convolutions, and even Fourier transforms (at least in certain cases). And in some ways, they even make life easier compared to functions. For example, every distribution is infinitely differentiable!"/>
<meta name="keywords" content=""/>
<meta name="robots" content="noodp"/>
<link rel="canonical" href="https://ejnnr.github.io/posts/distributions-intro/" />





<link rel="stylesheet" href="https://ejnnr.github.io/assets/style.css">


<link rel="stylesheet" href="https://ejnnr.github.io/style.css">


<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://ejnnr.github.io/img/apple-touch-icon-144-precomposed.png">
<link rel="shortcut icon" href="https://ejnnr.github.io/img/favicon.png">


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Distributions Part I: the Delta distribution"/>
<meta name="twitter:description" content="  Did you always want to know kind of object this weird Dirac delta &#34;function&#34;
  actually is? Well, it&#39;s a Schwartz distribution. If that doesn&#39;t help much,
  then keep reading.
  "/>



<meta property="og:title" content="Distributions Part I: the Delta distribution" />
<meta property="og:description" content="  Did you always want to know kind of object this weird Dirac delta &#34;function&#34;
  actually is? Well, it&#39;s a Schwartz distribution. If that doesn&#39;t help much,
  then keep reading.
  " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ejnnr.github.io/posts/distributions-intro/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-07-06T14:15:00&#43;02:00" />
<meta property="article:modified_time" content="2021-07-06T14:15:00&#43;02:00" /><meta property="og:site_name" content="Erik Jenner" />







  </head>
  <body class="">
    <div class="container">
      <header class="header">
  <span class="header__inner">
    <a href="/" class="logo" style="text-decoration: none;">
  
    <span class="logo__mark"><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" viewBox="0 0 44 44">
  <path fill="none" d="M15 8l14.729 14.382L15 35.367"/>
</svg>
</span>
    <span class="logo__text">Erik Jenner</span>
  
</a>

    <span class="header__right">
      
        <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
        
          <li><a href="/about">About</a></li>
        
      
      
    
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="/about">About</a></li>
      
    
  </ul>
</nav>

        <span class="menu-trigger">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M0 0h24v24H0z" fill="none"/>
            <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
          </svg>
        </span>
      
      <span class="theme-toggle">
        <svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>

      </span>
    </span>
  </span>
</header>


      <div class="content">
        
  
  

  <div class="post">
    <h1 class="post-title"><a href="https://ejnnr.github.io/posts/distributions-intro/">Distributions Part I: the Delta distribution</a></h1>
    <div class="post-meta">
      
        <span class="post-date">
          2021-07-06
        </span>

        
          
        
      

      
      
        <span class="post-read-time">â€” 9 min read</span>
      
    </div>

    

    

    <div class="post-content">
      
      <p>Schwartz distributions are a generalization of functions from \(\mathbb{R}^n\) to \(\mathbb{R}\):
strictly speaking, they aren&rsquo;t such functions themselves, but you can do a lot of the same
stuff with them that you can do with normal functions, such as taking derivatives, computing convolutions,
and even Fourier transforms (at least in certain cases).
And in some ways, they even make life easier compared to functions. For example, every distribution
is infinitely differentiable! But of course, we do have to give up some things: distributions
can&rsquo;t be evaluated at a single point and it&rsquo;s in general impossible to multiply two distributions.</p>
<p>In this series, we&rsquo;ll try to understand all of these properties of distributions and more.
I will focus on intuition but still <a href="/posts/state-formally-reason-informally/">give formal definitions</a> of all the concepts we look at.
As a secondary purpose, studying distributions will also be an excellent opportunity to
practice finding good definitions. We will introduce many different operations on distributions
and in each case, we will try to understand how one could come up with the definition
in a natural way.</p>
<h2 id="motivation">Motivation</h2>
<p>In electrostatics, <em>charge densities</em> are used to model the amount
of electric charge in different places. Such a charge density is a function
\(\rho: \mathbb{R}^3 \to \mathbb{R}\) that assigns an amount of charge per volume
to every point \(x \in \mathbb{R}^3\). From an experimental standpoint,
these densities are only useful abstractions; what we can measure is at best
the <em>total charge in some volume</em>. This charge \(Q\) is given by the integral
of the density over the volume:
\[Q(V) = \int_V \rho(x) dx\]
for any subset \(V \subseteq \mathbb{R}^3\). You can even think of this as
the <em>definition</em> of the density \(\rho\): the only thing we care about is that
when we measure the charge \(Q(V)\) in any volume \(V\), we get \(\int_V \rho(x) dx\).</p>
<p>Now assume we observe the following: \(Q(V) = 1\) for any volume \(V\) that contains
the origin but \(Q(V) = 0\) if \(V\) does not contain the origin. Intuitively, we
conclude that there is a point charge with value 1 in the origin and no charge anywhere else.
But how can we model this using a density \(\rho\)? If \(\rho\) is any (integrable)
function, as we originally assumed, then we must have \(\rho(x) = 0\) for \(x \neq 0\).<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>
But in that case, \(\int_V \rho(x) dx = 0\) for all volumes \(V\), which contradicts
our first observation.</p>
<p>For now, let&rsquo;s just &ldquo;define this problem away&rdquo;: we&rsquo;ll say that \(\rho(x) = \delta(x)\),
where \(\delta(x)\) is an object such that
\[\int_V \delta(x) dx := 1 \text{ if } 0 \in V, \text{ otherwise } 0.\]
The word &ldquo;object&rdquo; here is code for &ldquo;we&rsquo;re pretty confused and don&rsquo;t know what this thing
is but we&rsquo;d like to have something that behaves this way&rdquo;.</p>
<p>We&rsquo;ll develop a formal definition of \(\delta\) soon. But first, let&rsquo;s extend
the original example a bit: suppose instead of being interested only in the charge inside
some volume, we now introduce a charged test particle and want to know the potential
energy it has due to the charge density \(\rho\). This potential is given by
\[\Phi \propto \int_{\mathbb{R}^3} \frac{1}{|x_0 - x|} \rho(x) dx\]
for a test particle at position \(x_0\). So what is the potential energy if we have the point charge from
before, \(\rho(x) = \delta(x)\)? So far, we have only defined \(\int_V \delta(x) dx\),
and if \(\delta(x)\) appears anywhere else, we don&rsquo;t really know what to
do with it. Remember, \(\int_V \delta(x) dx\) is just a notation we introduced to mean
&ldquo;1 if \(0 \in V\) and 0 otherwise&rdquo;, it&rsquo;s not actually an integral in any usual sense.</p>
<p>So we will apply a powerful technique &ndash; wishful thinking. We just assume that
\(\delta(x)\) behaves the way we would intuitively like it to, and then worry later
about constructing something that actually does behave that way. Since for \(\rho(x) = \delta(x)\),
there is no charge outside the origin, all parts of the integral above except for \(x = 0\)
ought to vanish. So let&rsquo;s just write
\[\int_{\mathbb{R}^3} \frac{1}{|x_0 - x|}\delta(x) dx = \int_{\{0\}}\frac{1}{|x_0 - x|}\delta(x)dx.\]
Since we&rsquo;re only integrating over \(\{0\}\) now, we can set \(x = 0\) in \(|x_0 - x|\). Then
this part doesn&rsquo;t depend on \(x\) anymore and we get
\[\int_{\{0\}}\frac{1}{|x_0 - x|}\delta(x)dx = \frac{1}{|x_0|}\int_{\{0\}}\delta(x)dx.\]
But we know what to do with that last part, its' 1! So the potential should be \(\Phi \propto \frac{1}{|x_0|}\).</p>
<p>We can apply the same argument more generally to \(\int \varphi(x) \delta(x)dx\) for other functions \(\varphi\).
So let&rsquo;s &ldquo;wish&rdquo; that
\[\int_{\mathbb{R}^3} \varphi(x) \delta(x) dx := \varphi(0)\]
hold for all functions \(\varphi\). This contains our original definition of \(\delta(x)\) as a special
case, namely for the indicator function \(\varphi = 1_V\).</p>
<h2 id="schwartz-distributions">Schwartz distributions</h2>
<p>The defining property of \(\delta(x)\) that we would like to have is
\[\int_{\mathbb{R}^3} \delta(x) \varphi(x) dx := \varphi(0)\]
for arbitrary functions \(\varphi\). We have already noted that this cannot
be an actual (Lebesgue) integral, so it makes sense to get rid of that
notation. Instead, we will write
\[\langle \delta, \varphi\rangle := \varphi(0).\]
This hightlights the important part: \(\delta\) lets us take
any function \(\varphi\) and maps it to its value \(\varphi(0)\) at the origin. So \(\delta\)
is a function after all; just not from \(\mathbb{R}^3\) to \(\mathbb{R}\) but from
the space of <em>functions on</em> \(\mathbb{R}^3\) to \(\mathbb{R}\)!</p>
<p>\(\delta\) is one example of <em>Schwartz distributions</em> or <em>distributions</em> for short,
which are all maps from a space of functions to the real numbers. Let&rsquo;s make this
more precise:</p>
<p><strong>Definition:</strong> Let \(U \subseteq \mathbb{R}^n\) be an open subset. A <em>test function</em> on \(U\)
is a smooth, compactly supported function \(\varphi: U \to \mathbb{R}\) and we write
\(\mathcal{D}(U)\) for the space of all such test functions. A <em>Schwartz distribution</em>
on \(U\) is then a <em>continuous linear function</em> \(T: \mathcal{D}(U) \to \mathbb{R}\).
We write \(\mathcal{D}'(U)\) for the space of all such distributions on \(U\).</p>
<p>This definition requires some clarifications. First, Schwartz distributions are not
at all the same thing as probability distributions, and when I say &ldquo;distribution&rdquo;
in this series, I will always mean a Schwartz distribution. Second, if we want to
talk about continuity, we of course need to define a topology on the space \(\mathcal{D}(U)\)
of test functions. The topology we use here is called the <em>canonical LF topology</em> but
we won&rsquo;t discuss that any further in this post.</p>
<p>The name <em>test function</em> comes from the fact that these are the functions on which
we can &ldquo;test&rdquo;, i.e. evaluate distributions. In our first example about the total
charge in some volume, we used indicator functions \(1_V\) as test functions.
The \(\delta\) distribution would in principle work on <em>any</em> space of test functions.
But it turns out that a good choice for the general definition are smooth
compactly supported functions because this makes a lot of the theory very nice.</p>
<p>We will write \(\langle T, \varphi \rangle\) for the distribution \(T\) applied to
the test function \(\varphi\). But why did we write \(\int \delta(x) \varphi(x) dx\) before?
What does all of this have to do with integrals? The reason is the following:
let \(f : U \to \mathbb{R}\) be any locally integrable (read &ldquo;somewhat reasonable&rdquo;) function. Then the map
\[\varphi \mapsto \int_U f(x) \varphi(x) dx\]
defines a distribution on \(U\), which we denote by \(T_f\). This is the sense in which
distributions are <em>generalized</em> functions; each classical function induces a distribution.
So when we write \(\int \delta(x) \varphi(x) dx\), we are essentially pretending that
the delta distribution is induced by a function \(\delta(x)\). There is no such function,
but the notation is used very often anyway; probably in part for historical reasons
and in part because it turns out to work surprisingly well, as we&rsquo;ll see next.</p>
<p>We will revisit distributions in general in the next post but for now, we focus on the
\(\delta\) distribution again.</p>
<h2 id="variations-of-the--delta--distribution">Variations of the \(\delta\) distribution</h2>
<p>We now have a formal understanding of terms of the form \(\int \delta(x) \varphi(x)dx\).
But in practice, the \(\delta\) distribution often appears in modified versions,
such as in terms like
\[\int \delta(x - x_0)\varphi(x) dx\]
or
\[\int \delta(ax)\varphi(x)dx.\]
So far, we haven&rsquo;t formally defined these terms. That means it&rsquo;s time to apply
the Power of Wishful Thinking again, in order to find good definitions for them.</p>
<p>It&rsquo;s pretty clear what \(\delta(x - x_0)\) should mean: it&rsquo;s just a shifted version
of \(\delta(x)\), with its &ldquo;peak&rdquo; at \(x_0\) instead of \(0\). More explicitly, it
makes sense to demand that
\[\int \delta(x - x_0)\varphi(x) dx = \int \delta(x) \varphi(x + x_0) dx\]
as would be the case if \(\delta\) was a regular function (all integrations are assumed
to be over all of \(\mathbb{R}^n\)). Then we can see that
\[\int \delta(x - x_0)\varphi(x) dx = \varphi(x_0).\]</p>
<p>Let&rsquo;s consider \(\int \delta(ax)\varphi(x)dx\) instead. You might argue as follows:
&ldquo;\(\delta(ax) = 0\) for \(x \neq 0\), so we only need to consider \(x = 0\). In that case,
\(ax = 0 = x\), so \(\delta(ax)\) should be the same as \(\delta(x)\)&rdquo;.
But this is a misunderstanding caused by the (admittedly very confusing) notation
often used for the \(\delta\) distribution: \(\delta(x)\) doesn&rsquo;t mean that anything
is actually being evaluated at \(x\), it&rsquo;s just a notational convention <em>that only makes sense inside integrals</em>.
We don&rsquo;t want to demand that \(\delta(\cdot)\) behaves like functions when we plug in different things because
we never have \(\delta(x)\) appearing on its own anyway.</p>
<p>What we do want is that \(\delta(x)\) behaves like functions <em>inside an integral</em>.
In particular, for functions \(f\) and \(\varphi\) and a scalar \(a \neq 0\), we have
\[\int f(ax)\varphi(x)dx = \frac{1}{|a|^n}\int f(x)\varphi\left(\frac{x}{a}\right)dx.\]
So since we want \(\delta(x)\) to behave the way that functions behave inside integrals,
we define
\[\int \delta(ax)\varphi(x)dx := \frac{1}{|a|^n}\int\delta(x)\varphi\left(\frac{x}{a}\right)dx = \frac{1}{|a|^n}\varphi(0).\]</p>
<p>In fact, we can generalize this argument: for any diffeomorphism \(g\) of \(\mathbb{R}^n\), we have
\[\int f(g(x))\varphi(x)dx = \int |\operatorname{det} Dg(x)|^{-1} f(x)\varphi(g^{-1}(x))dx\]
where \(Dg\) is the derivative (Jacobian) of \(g\).
So in analogy, we can define \(\delta(g(x))\) for any diffeomorphism \(g\) by
\[\int \delta(g(x))\varphi(x)dx := \int |\operatorname{det} Dg(x)|^{-1} \delta(x)\varphi(g^{-1}(x))dx
= |\operatorname{det} Dg(0)|^{-1}\varphi(g^{-1}(0)).\]</p>
<p>I want to stress again that none of these arguments are &ldquo;proofs&rdquo; or &ldquo;derivations&rdquo; &ndash; in the end, we have
to choose how to define all of these terms. But clearly some definitions make more sense than others
and in the examples here there is clearly one &ldquo;right&rdquo; way to define what \(\delta(g(x))\) etc. should
mean. This will become even more clear in the next post: we will continue the theme of finding
good definitions via &ldquo;wishful thinking&rdquo;, only this time for arbitrary distributions and for many
more types of operations.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Actually, only for almost all \(x\) but that doesn&rsquo;t change anything.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

    </div>
    
      
        <div class="pagination">
          <div class="pagination__title">
            <span class="pagination__title-h">Read other posts</span>
            <hr />
          </div>
          <div class="pagination__buttons">
            
            
              <span class="button next">
                <a href="https://ejnnr.github.io/posts/automation-productivity/">
                  <span class="button__text">Scripting for personal productivity</span>
                  <span class="button__icon">â†’</span>
                </a>
              </span>
            
          </div>
        </div>
      
    


    
      
        

      
    

    </div>

      </div>

      
        <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright copyright--user"><div><a href='/legal'>Legal</a></div><div>Powered by Hugo. Theme: Hello Friend by panr</div></div>
    
  </div>
</footer>

<script src="https://ejnnr.github.io/assets/main.js"></script>
<script src="https://ejnnr.github.io/assets/prism.js"></script><script>
window.MathJax = {
  tex: {
    tags: 'ams'
  }
};
</script>
<script async src="/mathjax/tex-chtml.js"></script>




      
    </div>

    
  </body>
</html>
